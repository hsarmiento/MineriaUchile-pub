{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial para laboratorio 2.1 y 2.2: Clasificación\n",
    "\n",
    "Bárbara Poblete; José Miguel Herrera, Hernan Sarmiento.\n",
    "\n",
    "**16 de Abril 2018**\n",
    "\n",
    "\n",
    "## 1. Anaconda\n",
    "\n",
    "Para este laboratorio (sesiones 2.1 y 2.2) usaremos Python y algunas biblioteca para entrenar clasificadores. \n",
    "La forma más fácil de tener un ambiente de Python con todas las bibliotecas más comunes es instalar *Anaconda*.\n",
    "\n",
    "Para instalar *Anaconda*:\n",
    "- Descarga de aquí la última versión para Python 3.6 de tu plataforma: https://www.continuum.io/downloads\n",
    "- Sigue las instrucciones de instalación en \"How to install ANACONDA\".\n",
    "- Asegúrate de dejar en el PATH el directorio `bin` de anaconda. Puedes probar tu instalación ejecutando `python` en un terminal y verificar que diga algo como `Python 3.6.1 |Anaconda 4.4.0` al principio.\n",
    "\n",
    "**Nota:** Anaconda facilita mucho la instalación de las bibliotecas que usaremos en este laboratorio. Instalar las bibliotecas (`scikit-learn`, `jupyter`) desde cero puede ser un poco complicado si no estás seguro/a de lo que estás haciendo. Por lo tanto, instalar Anaconda es altamente recomendado para estas sesiones de laboratorio.\n",
    "\n",
    "\n",
    "## 2. Jupyter\n",
    "\n",
    "**Jupyter notebook** es una aplicación Web que permite crear documentos con código Python, similar a los R Notebooks o R Markdown. De hecho los enunciados del lab 1.1 y 1.2 lo hicimos en R Markdown.\n",
    "En estos laboratorios usaremos un **notebook** donde deberas completar sus respuestas en el mismo archivo, y además, podrás verificar sus respuestas de inmediato. \n",
    "\n",
    "De hecho, para practicar puedes descargar este mismo notebook (tutorial2.ipynb).\n",
    "Para descargarlo anda a https://github.com/jotixh/MineriaUchile-pub/tree/master/tutoriales/, clic derecho en *tutorial2.ipynb* y descargar como. \n",
    "Luego, puedes cargarlo localmente ejecutando **jupyter notebook** en la terminal de su computador. Procura estar parado en el directorio que contiene el archivo .ipynb.\n",
    "\n",
    "Por ejemplo, si descargaste este mismo notebook en el directorio **tutoriales/**, entonces puedes cargarlo usando:\n",
    "\n",
    "```cd tutoriales/\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Luego selecciona el archivo .ipynb y podrás comenzar a editar el notebook. \n",
    "\n",
    "**TIP: con Shift-Enter puedes ejecutar cada bloque del notebook.**\n",
    "\n",
    "\n",
    "## 3. Scikit-learn\n",
    "\n",
    "Hay muchas bibliotecas para hacer análisis de datos. \n",
    "Para este laboratorio (y probablemente para los siguientes), vamos a usar `scikit-learn` (http://scikit-learn.org) que contiene muchos modelos de machine learning ya instalados. \n",
    "\n",
    "**OJO**: Si ya instalaste *Anaconda*, no necesitas instalar nada dado que viene en el pack.\n",
    "\n",
    "Para el resto del tutorial, asumiremos que estás usando este mismo notebook. \n",
    "\n",
    "Para cargar las bibliotecas, haz click en el siguiente bloque de código, y ejecútalo presionando `Shift+Enter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "print(\"Si se muestra esto es porque ya está instalado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Ejemplo: Iris Dataset\n",
    "\n",
    "Vamos a usar un dataset muy usado y que aparece en muchos sitios web. El dataset se llama **iris**, y corresponde a un conjunto de datos que contiene 3 clases  El método **load_iris** permite cargar el Iris dataset, que contiene 150 **instancias** (filas) de 3 **clases** diferentes de flores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data      ## datos, caracteristicas o features de cada flor. \n",
    "y = iris.target    ## clase para cada instancia anterior.\n",
    "\n",
    "print(\"X:\\n\", X[:10])   # muestra las primeras 10 filas que corresponden a las caracteristicas de 10 flores. \n",
    "print(\"y:\\n\", y[:10])   # muestra las primeras 10 clases para cada una de las instancias de X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos saber los nombres de los *features* (columnas) usando el campo **feature_names**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber cuáles son las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(iris.target[1:150])  # mostramos las todas las clases de X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 Corresponde a setosa \n",
    "\n",
    "1 Corresponde a versicolor\n",
    "\n",
    "2 Corresponde a virginica\n",
    "\n",
    "Podemos verificar esto haciendo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, lo que tenemos es la descripción de una flor (medidas) en una fila acompañada con la clase. \n",
    "\n",
    "Por ejemplo, para la segunda fila, tenemos:\n",
    "\n",
    "**4.9,  3. ,  1.4,  0.2**  y la clase asociada es **0 (setosa)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener una descripción más completa usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos a continuación será entrenar un clasificador y predecir con nuevos datos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Nuestro primer clasificador\n",
    "\n",
    "Entrenaremos nuestro primer clasificador con el *Iris dataset*. \n",
    "Para esto, usaremos un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)   ## Entrenar usando X (features), y (clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método **fit** entrenamos el clasificador con los datos de **X** y la clase asociada a cada uno, **y**. Para ver qué tan bien fue el entrenamiento, podemos evaluar el clasificador ejecutándolo sobre instancias y verificando que la clase sea la correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ya hemos entrenado nuestro clasificador empleando **fit**. Luego para predecir, usamos **predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)   ## predecir la matriz X, los resultados (clases predecidas) quedan en y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si ejecutáramos ```clf.predict([[1.0, 2.0, 3.0, 1.0 ... etc]])```, le estamos pasando al clasificador un dato con valores **[1.0, 2.0, 3.0, 1.0 ... etc]**. Al ejecutar **predict**, éste nos retornará un arreglo con el valor **0**, indicando que esos datos fueron clasificados como la clase **0**.\n",
    "\n",
    "En **scikit-learn** existe el método **accuracy_score** que computa el Accuracy de la clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, tuvimos un accuracy del 100% con el clasificador (1.0). Sin embargo, **hicimos algo incorrecto**: evaluamos el clasificador con los mismos datos con los cuales lo entrenamos! \n",
    "\n",
    "Al hacer esto, lo que terminamos haciendo fue *aprender de los datos de entrada* y evaluamos (o testeamos) usando los mismos datos. Esto también se denomina **overfitting**. \n",
    "\n",
    "También podríamos ver otras métricas como precision, recall y f-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde luego, la clasificación es perfecta. Para tener un resultado más realista de la clasificación vamos a dividir el dataset en dos: en **training set** y en un **test set**.\n",
    "\n",
    "El **training_set** nos permite aprender de ejemplos y ajustar el clasificador de acuerdo a éstos. \n",
    "El **test_set** nos permitirá comprender qué tan bien **generalizamos** con el clasificador con nuevos datos. \n",
    "\n",
    " En **scikit-learn** existe un método llamado **train_test_split**, que nos permite hacer esta separación de manera aleatoria y estratificada (es decir, manteniendo la proporción de clases entre las instancias de cada set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=37, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método nos retorna cuatro listas, los correspondientes a train y a test. Es decir, para el entrenamiento se usará **X_train** que tiene los features de entreamiento e **y_train** que son las clases. Así mismo, para  probar con nuevos datos (testing), usaremos **X_test** como los features de entreda e **y_test** las clases. \n",
    "\n",
    "El parámetro **test_size** nos permite regular la fracción de los datos que irán a test; en este caso 33% del dataset completo. \n",
    "\n",
    "El parámetro **random_state** nos permite fijar la semilla para tener resultados consistentes (genera la misma partición de datos). Si ejecutamos el método varias veces con la misma semilla, nos mostrará los mismos resultados siempre. \n",
    "\n",
    "El parámetro **stratify** recibe un arreglo con la distribución de clases, y el método intenta mantener esa misma distribución en las listas resultantes. Si no hicieramos esto, podríamos, por ejemplo, tener muchos datos de una clase en el set de entrenamiento. \n",
    "\n",
    "Ahora, al fin, podemos probar nuestro clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)    ## Entrenamos con X_train y clases y_train\n",
    "\n",
    "y_pred = clf.predict(X_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y_test, y_pred))   ## Evaluamos la predicción con lo que debería dar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios Finales\n",
    "\n",
    "* Observe detenidamente el código anterior para entender qué estamos haciendo.\n",
    "\n",
    "* Llegue al laboratorio preparado con los conceptos de **Accuracy**, **Precision**, **Recall**, **F-score** y **cross validation**.\n",
    "\n",
    "* Descague este dataset que será usado en la sesión 2.2: https://users.dcc.uchile.cl/~jherrera/mineria/datasets/unbalanced.csv\n",
    "\n",
    "* Asegurese antes de la sesión que las siguientes bibliotecas ya están instaladas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics, cross_validation\n",
    "\n",
    "\n",
    "print(\"Si muestra este mensaje es porque la carga de las librerías anteriores está ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
